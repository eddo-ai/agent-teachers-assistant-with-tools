"""Streamlit page demonstrating LangGraph streaming capabilities and modes."""

from typing import Any, Iterator
from uuid import uuid4

import streamlit as st
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig

from agent_arcade_tools.graph import graph

langgraph_url: Any | str = st.secrets.get("LANGGRAPH_API_URL", "http://localhost:2024")

st.title("Streaming modes")

st.write(
    """
This is a demo of the various streaming modes supported by LangGraph Runnables.
         
When using stream() or astream() with chat models, the output is streamed as AIMessageChunks as it is generated by the LLM. This allows you to present or process the LLM's output incrementally as it's being produced, which is particularly useful in interactive applications or interfaces.
Usage with LangGraph

LangGraph compiled graphs are Runnables and support the standard streaming APIs.

When using the stream and astream methods with LangGraph, you can choose one or more streaming mode which allow you to control the type of output that is streamed. The available streaming modes are:

    "values": Emit all values of the state for each step.
    "updates": Emit only the node name(s) and updates that were returned by the node(s) after each step.
    "debug": Emit debug events for each step.
    "messages": Emit LLM messages token-by-token.
    "custom": Emit custom output written using LangGraph's StreamWriter.

"""
)

with st.sidebar:
    st.write("LangGraph URL: ", langgraph_url)

# Select a mode
st.selectbox(
    "Select a mode", ["values", "updates", "debug", "messages", "custom"], key="mode"
)


def handle_stream_response(
    response: Iterator[dict[str, Any] | Any], config: RunnableConfig
) -> None:
    """Handle streaming response, including interrupts for authorization."""
    try:
        for chunk in response:
            if isinstance(chunk, dict) and "__interrupt__" in chunk:
                # Extract the interrupt data
                interrupt_data = chunk["__interrupt__"][0]

                # Display authorization UI
                st.warning("Authorization Required")
                st.markdown(interrupt_data.value)

                # Show additional interrupt info
                with st.expander("Debug Info"):
                    st.json(
                        {
                            "resumable": interrupt_data.resumable,
                            "when": interrupt_data.when,
                            "ns": (
                                interrupt_data.ns
                                if hasattr(interrupt_data, "ns")
                                else None
                            ),
                        }
                    )

                if st.button("Authorize"):
                    # Resume streaming with None input - graph will handle auth state
                    new_response = graph.stream(
                        input=None,
                        config=config,
                        stream_mode=st.session_state.get("mode", "values"),
                    )
                    handle_stream_response(new_response, config)
                    return
            else:
                st.write(chunk)
    except Exception as e:
        st.error(f"Error during streaming: {str(e)}")


if st.button("Run"):
    st.session_state.thread_id = str(uuid4())
    with st.chat_message("assistant"):
        config: RunnableConfig = RunnableConfig(
            configurable={
                "thread_id": st.session_state.thread_id,
                "user_id": st.session_state.get("user_id", "aw+test@eddolearning.com"),
            },
            callbacks=[StreamlitCallbackHandler(st.container())],
        )
        response: Iterator[dict[str, Any] | Any] = graph.stream(
            input={"messages": [HumanMessage(content="Check my email")]},
            config=config,
            stream_mode=st.session_state.get("mode", "values"),
        )
        handle_stream_response(response, config)
